{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d180707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import expit\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8e155f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegressionWithEntropyRegularization(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, lambda_=0.1, max_iter=10, tol=1e-4):\n",
    "        self.C = C\n",
    "        self.lambda_ = lambda_\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.classes_ = None\n",
    "        self.le = None\n",
    "    \n",
    "    def _loss_function(self, X, y, p):\n",
    "        entropy = -np.sum(p * np.log(p), axis=1)\n",
    "        return -np.mean(y * np.log(p) + (1 - y) * np.log(1 - p)) + self.lambda_ * np.mean(entropy)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Convert labels to numeric values (0, 1)\n",
    "        self.le = LabelEncoder()\n",
    "        y = self.le.fit_transform(y)\n",
    "\n",
    "        # Initialize the coefficients\n",
    "        self.coef_ = np.zeros(X.shape[1])\n",
    "        self.intercept_ = 0.0\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Compute the logits\n",
    "            z = self.intercept_ + np.dot(X, self.coef_)\n",
    "    \n",
    "            # Compute the probabilities using the sigmoid function\n",
    "            p = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "            # Compute the gradient of the loss function\n",
    "            gradient = np.dot(X.T, (p - y)) / len(y)\n",
    "    \n",
    "            # Compute the Hessian matrix\n",
    "            hessian = np.dot(X.T * p * (1 - p), X) / len(y)\n",
    "    \n",
    "            # Update the coefficients\n",
    "            self.coef_ -= np.linalg.solve(hessian + self.lambda_ * np.eye(X.shape[1]), gradient)\n",
    "            self.intercept_ -= np.mean(p - y) / (self.lambda_ + 1e-8)\n",
    "    \n",
    "            # Check convergence\n",
    "            if np.linalg.norm(gradient) < self.tol:\n",
    "                break\n",
    "\n",
    "        self.classes_ = self.le.classes_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Compute the logits\n",
    "        z = self.intercept_ + np.dot(X, self.coef_)\n",
    "\n",
    "        # Compute the probabilities using the sigmoid function\n",
    "        p = 1 / (1 + np.exp(-z))\n",
    "\n",
    "        # Convert probabilities to class labels (0 or 1)\n",
    "        y_pred = np.where(p >= 0.5, 1, 0)\n",
    "\n",
    "        # Convert class labels back to original labels\n",
    "        y_pred = self.le.inverse_transform(y_pred)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Compute the logits\n",
    "        z = self.intercept_ + np.dot(X, self.coef_)\n",
    "\n",
    "        # Compute the probabilities using the sigmoid function\n",
    "        p = expit(z)\n",
    "\n",
    "        # Return the class probabilities\n",
    "        return np.column_stack((1 - p, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfde5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"penguins_size.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47215589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
       "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
       "5  Adelie  Torgersen              39.3             20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "4       3450.0  FEMALE  \n",
       "5       3650.0    MALE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ada142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sex'] != '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ecb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.get_dummies(df.drop('species', axis=1), drop_first=True)\n",
    "y = df['species']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18c9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e8124da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4ca018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the custom logistic regression class\n",
    "log_model = LogisticRegressionWithEntropyRegularization(C=1.0, lambda_=0.1, max_iter=10, tol=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4d6223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionWithEntropyRegularization()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionWithEntropyRegularization</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionWithEntropyRegularization()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionWithEntropyRegularization()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "log_model.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4dc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = log_model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df14401e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e96278cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[31  0]\n",
      " [ 0 12]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2446518",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      1.00      1.00        31\n",
      "   Chinstrap       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        43\n",
      "   macro avg       1.00      1.00      1.00        43\n",
      "weighted avg       1.00      1.00      1.00        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report\n",
    "classification_report_ = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1da1c7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      1.00      1.00       115\n",
      "   Chinstrap       1.00      1.00      1.00        56\n",
      "\n",
      "    accuracy                           1.00       171\n",
      "   macro avg       1.00      1.00      1.00       171\n",
      "weighted avg       1.00      1.00      1.00       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training data\n",
    "y_train_pred = log_model.predict(scaled_X_train)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "print(\"Training Set Performance:\")\n",
    "print(train_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6565a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b42fec00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      1.00      1.00        31\n",
      "   Chinstrap       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        43\n",
      "   macro avg       1.00      1.00      1.00        43\n",
      "weighted avg       1.00      1.00      1.00        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_test_pred = log_model.predict(scaled_X_test)\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "print(\"Test Set Performance:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ab4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
